{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBM_vectors_Speaker_Tracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IrWLvXP_2jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsjkV-e2ITBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u24Zyq5FOcHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from __future__ import print_function\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_FkiE1mrS38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from python_speech_features import mfcc\n",
        "from sklearn import preprocessing\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6SrhJ0ZxQiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_x_init(fan_in, fan_out, dtype=np.float32):\n",
        "    k =  np.sqrt(6.0 / (fan_in + fan_out))\n",
        "    return tf.random_uniform((fan_in, fan_out), minval=-k, maxval=k, dtype=dtype)\n",
        "\n",
        "\n",
        "def sample_bernoulli(probs):\n",
        "    return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NNcGmW2yOjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class RBM:\n",
        "    def __init__(self,\n",
        "                 n_visible,\n",
        "                 n_hidden,\n",
        "                 learning_rate=0.01,\n",
        "                 momentum=0.95,\n",
        "                 err_function='mse',\n",
        "                 use_tqdm=False,\n",
        "                 # DEPRECATED:\n",
        "                 tqdm=None):\n",
        "        if not 0.0 <= momentum <= 1.0:\n",
        "            raise ValueError('momentum should be in range [0, 1]')\n",
        "\n",
        "       \n",
        "\n",
        "        self._use_tqdm = use_tqdm\n",
        "        self._tqdm = None\n",
        "\n",
        "        if use_tqdm or tqdm is not None:\n",
        "            from tqdm import tqdm\n",
        "            self._tqdm = tqdm\n",
        "\n",
        "        self.n_visible = n_visible\n",
        "        self.n_hidden = n_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.x = tf.placeholder(tf.float32, [None, self.n_visible])\n",
        "        self.y = tf.placeholder(tf.float32, [None, self.n_hidden])\n",
        "\n",
        "        self.w = tf.Variable(tf_x_init(self.n_visible, self.n_hidden), dtype=tf.float32)\n",
        "        self.visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n",
        "        self.hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n",
        "\n",
        "        self.delta_w = tf.Variable(tf.zeros([self.n_visible, self.n_hidden]), dtype=tf.float32)\n",
        "        self.delta_visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n",
        "        self.delta_hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n",
        "\n",
        "        self.update_weights = None\n",
        "        self.update_deltas = None\n",
        "        self.compute_hidden = None\n",
        "        self.compute_visible = None\n",
        "        self.compute_visible_from_hidden = None\n",
        "\n",
        "        self._initialize_vars()\n",
        "\n",
        "        assert self.update_weights is not None\n",
        "        assert self.update_deltas is not None\n",
        "        assert self.compute_hidden is not None\n",
        "        assert self.compute_visible is not None\n",
        "        assert self.compute_visible_from_hidden is not None\n",
        "\n",
        "        \n",
        "        self.compute_err = tf.reduce_mean(tf.square(self.x - self.compute_visible))\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def _initialize_vars(self):\n",
        "        pass\n",
        "\n",
        "    def get_err(self, batch_x):\n",
        "        return self.sess.run(self.compute_err, feed_dict={self.x: batch_x})\n",
        "\n",
        "\n",
        "\n",
        "    def partial_fit(self, batch_x):\n",
        "        self.sess.run(self.update_weights + self.update_deltas, feed_dict={self.x: batch_x})\n",
        "\n",
        "    def fit(self,\n",
        "            data_x,\n",
        "            n_epoches=10,\n",
        "            batch_size=10,\n",
        "            shuffle=True,\n",
        "            verbose=True):\n",
        "        assert n_epoches > 0\n",
        "\n",
        "        n_data = data_x.shape[0]\n",
        "\n",
        "        if batch_size > 0:\n",
        "            n_batches = n_data // batch_size + (0 if n_data % batch_size == 0 else 1)\n",
        "        else:\n",
        "            n_batches = 1\n",
        "\n",
        "        if shuffle:\n",
        "            data_x_cpy = data_x.copy()\n",
        "            inds = np.arange(n_data)\n",
        "        else:\n",
        "            data_x_cpy = data_x\n",
        "\n",
        "        errs = []\n",
        "\n",
        "        for e in range(n_epoches):\n",
        "            if verbose and not self._use_tqdm:\n",
        "                print('Epoch: {:d}'.format(e))\n",
        "\n",
        "            epoch_errs = np.zeros((n_batches,))\n",
        "            epoch_errs_ptr = 0\n",
        "\n",
        "            if shuffle:\n",
        "                np.random.shuffle(inds)\n",
        "                data_x_cpy = data_x_cpy[inds]\n",
        "\n",
        "            r_batches = range(n_batches)\n",
        "\n",
        "            if verbose and self._use_tqdm:\n",
        "                r_batches = self._tqdm(r_batches, desc='Epoch: {:d}'.format(e), ascii=True, file=sys.stdout)\n",
        "\n",
        "            for b in r_batches:\n",
        "                batch_x = data_x_cpy[b * batch_size:(b + 1) * batch_size]\n",
        "                self.partial_fit(batch_x)\n",
        "                batch_err = self.get_err(batch_x)\n",
        "                epoch_errs[epoch_errs_ptr] = batch_err\n",
        "                epoch_errs_ptr += 1\n",
        "\n",
        "            if verbose:\n",
        "                err_mean = epoch_errs.mean()\n",
        "                if self._use_tqdm:\n",
        "                    self._tqdm.write('Train error: {:.4f}'.format(err_mean))\n",
        "                    self._tqdm.write('')\n",
        "                else:\n",
        "                    print('Train error: {:.4f}'.format(err_mean))\n",
        "                    print('')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "            errs = np.hstack([errs, epoch_errs])\n",
        "\n",
        "        return errs\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.sess.run(self.w),\\\n",
        "            self.sess.run(self.visible_bias),\\\n",
        "            self.sess.run(self.hidden_bias)\n",
        "\n",
        "    def save_weights(self, filename, name):\n",
        "        saver = tf.train.Saver({name + '_w': self.w,\n",
        "                                name + '_v': self.visible_bias,\n",
        "                                name + '_h': self.hidden_bias})\n",
        "        return saver.save(self.sess, filename)\n",
        "\n",
        "    def set_weights(self, w, visible_bias, hidden_bias):\n",
        "        self.sess.run(self.w.assign(w))\n",
        "        self.sess.run(self.visible_bias.assign(visible_bias))\n",
        "        self.sess.run(self.hidden_bias.assign(hidden_bias))\n",
        "\n",
        "    def load_weights(self, filename, name):\n",
        "        saver = tf.train.Saver({name + '_w': self.w,\n",
        "                                name + '_v': self.visible_bias,\n",
        "                                name + '_h': self.hidden_bias})\n",
        "        saver.restore(self.sess, filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2aXzje7yWU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class GBRBM(RBM):\n",
        "    def __init__(self, n_visible, n_hidden, **kwargs):\n",
        "       \n",
        "\n",
        "        RBM.__init__(self, n_visible, n_hidden, **kwargs)\n",
        "\n",
        "    def _initialize_vars(self):\n",
        "        hidden_p = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n",
        "        visible_recon_p = tf.matmul(sample_bernoulli(hidden_p), tf.transpose(self.w)) + self.visible_bias\n",
        "\n",
        "        \n",
        "\n",
        "        hidden_recon_p = tf.nn.sigmoid(tf.matmul(visible_recon_p, self.w) + self.hidden_bias)\n",
        "\n",
        "        positive_grad = tf.matmul(tf.transpose(self.x), hidden_p)\n",
        "        negative_grad = tf.matmul(tf.transpose(visible_recon_p), hidden_recon_p)\n",
        "\n",
        "        def f(x_old, x_new):\n",
        "            return self.momentum * x_old +\\\n",
        "                   self.learning_rate * x_new * (1 - self.momentum) / tf.to_float(tf.shape(x_new)[0])\n",
        "\n",
        "        delta_w_new = f(self.delta_w, positive_grad - negative_grad)\n",
        "        delta_visible_bias_new = f(self.delta_visible_bias, tf.reduce_mean(self.x - visible_recon_p, 0))\n",
        "        delta_hidden_bias_new = f(self.delta_hidden_bias, tf.reduce_mean(hidden_p - hidden_recon_p, 0))\n",
        "\n",
        "        update_delta_w = self.delta_w.assign(delta_w_new)\n",
        "        update_delta_visible_bias = self.delta_visible_bias.assign(delta_visible_bias_new)\n",
        "        update_delta_hidden_bias = self.delta_hidden_bias.assign(delta_hidden_bias_new)\n",
        "\n",
        "        update_w = self.w.assign(self.w + delta_w_new)\n",
        "        update_visible_bias = self.visible_bias.assign(self.visible_bias + delta_visible_bias_new)\n",
        "        update_hidden_bias = self.hidden_bias.assign(self.hidden_bias + delta_hidden_bias_new)\n",
        "\n",
        "        self.update_deltas = [update_delta_w, update_delta_visible_bias, update_delta_hidden_bias]\n",
        "        self.update_weights = [update_w, update_visible_bias, update_hidden_bias]\n",
        "\n",
        "        self.compute_hidden = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n",
        "        self.compute_visible = tf.matmul(self.compute_hidden, tf.transpose(self.w)) + self.visible_bias\n",
        "        self.compute_visible_from_hidden = tf.matmul(self.y, tf.transpose(self.w)) + self.visible_bias\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhEkb8RAaX8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessor\n",
        "# Here Bulk data is preprocessed to use in training\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s_AaIoqUcqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c5e7f18c-dc5a-4d3a-c6a7-bf5d07b4ee8e"
      },
      "source": [
        "shift = 1\n",
        "merge_limit=4\n",
        "dataset = []\n",
        "\n",
        "\n",
        "#name of the file where urbm model learned weights and biases will be saved.\n",
        "save_weights_path = \"/content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_model\" \n",
        "\n",
        "\n",
        "lr  = 0.001\n",
        "input_dim =80\n",
        "hidden_dim = 400\n",
        "batch_size = 100\n",
        "nb_epoch = 100\n",
        "\n",
        "# this is the directory where all test wav data\n",
        "# each file corresponds to each speaker\n",
        "path_dir = \"/content/gdrive/My Drive/SpeakerVerification/Data/\" \n",
        "file_list=os.listdir(path_dir)\n",
        "\n",
        "print(file_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['file_example_WAV_2MG.wav', 'taunt.wav', 'StarWars60.wav', 'StarWars3.wav', 'ortalking.wav', '3peopletalking.wav', 'OSR_us_000_0010_8k.wav', 'OSR_us_000_0011_8k.wav', 'OSR_us_000_0012_8k.wav', 'OSR_us_000_0013_8k.wav', 'OSR_us_000_0030_8k.wav', 'OSR_us_000_0031_8k.wav', 'OSR_us_000_0032_8k.wav', 'OSR_us_000_0034_8k.wav', 'OSR_us_000_0035_8k.wav', 'OSR_us_000_0036_8k.wav']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcEbpfXBHW0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f9128798-4fa9-40cf-abc3-b5fb855b7eb5"
      },
      "source": [
        "# create small segements for tracking audio file ... Target speaker are already extracted..\n",
        "tracking_file = '3peopletalking.wav'\n",
        "path=os.path.join(path_dir,tracking_file)\n",
        "\n",
        "(rate,sig) = wav.read(path)\n",
        "\n",
        "mfcc_feat = mfcc(sig,rate,numcep=20,nfft=1200)\n",
        "\n",
        "total_points = mfcc_feat.shape[0]  # total_points \n",
        "small_segment_length = 3000        # length of a small segment in ms\n",
        "mfcc_point_length = 25              # in ms\n",
        "shift_length = 10 \n",
        "\n",
        "# number of mfcc features per small segement \n",
        "mfcc_points_per_segment =  ( small_segment_length - mfcc_point_length ) // shift_length + 1   \n",
        "\n",
        "print(\"total points: \", end=\"\")\n",
        "print(total_points)\n",
        "\n",
        "print(\"small segment length: \", end=\"\")\n",
        "print(small_segment_length)\n",
        "\n",
        "print(\"mfcc points per segment: \", end=\"\")\n",
        "print(mfcc_points_per_segment)\n",
        "\n",
        "segment_list = []\n",
        "for i in range(0, total_points, mfcc_points_per_segment):\n",
        "    if(i+mfcc_points_per_segment>=total_points):    # the last segment can be less than normal size\n",
        "        break\n",
        "    else:\n",
        "        segment = np.array(mfcc_feat[ i : i + mfcc_points_per_segment - 1 ])\n",
        "\n",
        "    # print(segment)\n",
        "    segment_list.append(segment)\n",
        "\n",
        "small_segments = np.array(segment_list)\n",
        "\n",
        "print(small_segments.shape)\n",
        "# print(small_segments)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total points: 10911\n",
            "small segment length: 3000\n",
            "mfcc points per segment: 298\n",
            "(36, 297, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqK2g_UkVdpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility function to calculate divergence shape\n",
        "def D(s1,s2):\n",
        "    C1=np.cov(s1)\n",
        "    C2=np.cov(s2)\n",
        "\n",
        "    C1_inv = np.linalg.inv(C1)\n",
        "    C2_inv = np.linalg.inv(C2)\n",
        "\n",
        "    sub = np.subtract(C1 , C2)\n",
        "    inv_sub=np.subtract(C1_inv ,C2_inv)\n",
        "\n",
        "    res = np.multiply(sub,inv_sub)\n",
        "\n",
        "    trace = 0.5 * np.trace(res)\n",
        "\n",
        "    return trace\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l51VLKX4L65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# detecting speaker change points and large segments\n",
        "alpha = 2 \n",
        "S=small_segments\n",
        "\n",
        "cum_div = prev_d = D( S[0] , S[1] )\n",
        "\n",
        "start = 0 \n",
        "large_segments = []\n",
        "for i in range(S.shape[0]-2):\n",
        "    thres = alpha * cum_div / i ;\n",
        "    cur_d = D(S[i],S[i+1])\n",
        "    next_d = D(S[i],S[i+2])\n",
        "\n",
        "    if(cur_d>next_d and cur_d>prev_d and cur_d > thres):  # speaker change occurs\n",
        "        ls = S[start]\n",
        "        for j in range(start+1,i):\n",
        "            ls = np.concatenate((ls,S[j]),axis=0)\n",
        "        \n",
        "        large_segments.append(ls)\n",
        "        start=i\n",
        "\n",
        "        prev_d= D(S[i],S[i+1])\n",
        "        i+=1\n",
        "\n",
        "        cum_div = 0\n",
        "    else:\n",
        "        prev_d = cur_d\n",
        "    \n",
        "    cum_div +=cur_d;\n",
        "\n",
        "print(len(large_segments))\n",
        "print(large_segments[0].shape)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTnOEVrAOsLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " merge_limit = 4 \n",
        " refined_segments=[]  \n",
        " for i in range(len(large_segments)):\n",
        "    mfcc_feat=large_segments[i] \n",
        "    length  = mfcc_feat.shape[0] \n",
        "    # print(length)\n",
        "    dataset = []\n",
        "    for i in range(length-merge_limit+1):\n",
        "        temp=list(mfcc_feat[i])+list(mfcc_feat[i+1])+list(mfcc_feat[i+2])+list(mfcc_feat[i+3])\n",
        "        dataset.append(temp)\n",
        "    # print(len(temp))\n",
        "\n",
        "    # per speaker augmented data\n",
        "    augmented_dataset=np.array(dataset)                          # dataset\n",
        "    augmented_dataset_mvn=preprocessing.scale(augmented_dataset) # augmented dataset\n",
        "    # print(augmented_dataset_mvn.shape)\n",
        "    data=augmented_dataset_mvn\n",
        "\n",
        "    refined_segments.append(data)\n",
        "\n",
        "# print(len(refined_segments))\n",
        "# print(refined_segments[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLa3tqP9vClG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training for each large segments. or RBM adaptation for each large segments\n",
        "for i in range(len(refined_segments)):\n",
        "\n",
        "    data = refined_segments[i]\n",
        "\n",
        "    gbrbm = GBRBM(n_visible=input_dim, n_hidden=hidden_dim, learning_rate=lr, momentum=0.95, use_tqdm=True)\n",
        "    gbrbm.load_weights(save_weights_path,'weights')\n",
        "    errs = gbrbm.fit(data, n_epoches=nb_epoch, batch_size=batch_size)\n",
        "    name = 'weights'+f ;\n",
        "    #save each speaker into different folder\n",
        "    gbrbm.save_weights(save_weights_path+'track'+str(i),'weights'+'track'+str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_ujrlqDX-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ae6afe7d-d707-4fe1-ec7a-005edb072b7d"
      },
      "source": [
        "# RBM supervector generation ....\n",
        "import numpy as np\n",
        "\n",
        "supervector_list=[]\n",
        "\n",
        "for i in range(len(refined_segments)):\n",
        "    \n",
        "\n",
        "    gbrbm = GBRBM(n_visible=input_dim, n_hidden=hidden_dim, learning_rate=lr, momentum=0.95, use_tqdm=True)\n",
        "    gbrbm.load_weights(save_weights_path+'track'+str(i),'weights'+'track'+str(i))\n",
        "    w,b_bias,h_bias = gbrbm.get_weights()\n",
        "\n",
        "    w=np.reshape(w,80*400)\n",
        "    supervector=np.concatenate((w,b_bias,h_bias),axis=None)\n",
        "    # print(supervector.size)\n",
        "    # supervector=preprocessing.scale(supervector) # mean normalization of supervectors\n",
        "    # print(supervector)\n",
        "    supervector_list.append(supervector)\n",
        "\n",
        "# single speaker \n",
        "gbrbm.load_weights(save_weights_path+'ortalking.wav','weights'+'ortalking.wav')\n",
        "w,b_bias,h_bias = gbrbm.get_weights()\n",
        "\n",
        "w=np.reshape(w,80*400)\n",
        "supervector=np.concatenate((w,b_bias,h_bias),axis=None)\n",
        "# print(supervector.size)\n",
        "# supervector=preprocessing.scale(supervector) # mean normalization of supervectors\n",
        "# print(supervector)\n",
        "supervector_list.append(supervector)\n",
        "# # fit current size of the ram\n",
        "# trunk_sv_list=[]\n",
        "# for item in supervector_list:\n",
        "#     new_item=item[:15000]\n",
        "#     trunk_sv_list.append(new_item)\n",
        "# trunk_vectors= np.array(trunk_sv_list)\n",
        "# print(trunk_vectors.shape)\n",
        "# #\n",
        "\n",
        "supervector_data=np.array(supervector_list)\n",
        "#normalization\n",
        "supervector_data=preprocessing.scale(supervector_data, axis=0)\n",
        "\n",
        "# gbrbm = GBRBM(n_visible=input_dim, n_hidden=hidden_dim, learning_rate=lr, momentum=0.95, use_tqdm=True)\n",
        "# gbrbm.load_weights(save_weights_path,'weights')\n",
        "# w,b_bias,h_bias = gbrbm.get_weights()\n",
        "\n",
        "\n",
        "# w=np.reshape(w,80*400)\n",
        "# urbm_supervector=np.concatenate((w,b_bias,h_bias),axis=None)\n",
        "# print(supervector.size)\n",
        "# u_vector=preprocessing.scale(urbm_supervector) # mean normalization of supervectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modeltrack0\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modeltrack1\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modeltrack2\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modeltrack3\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modeltrack4\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modeltrack5\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modeltrack6\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_modelortalking.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaqfxI_wwIoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "130e16d3-09d8-49b1-d366-919d09f68ef5"
      },
      "source": [
        "# PCA whitening and dimensionality reduction  ...and finally RBM vectors for segments\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "X=supervector_data\n",
        "pca.fit(X)\n",
        "rbm_vectors= pca.transform(X)\n",
        "\n",
        "print(rbm_vectors.shape)\n",
        "print(rbm_vectors)\n",
        "print(len(rbm_vectors))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 8)\n",
            "[[-1.75298214e+01  1.30813522e+01  3.55296745e+01 -5.45067406e+01\n",
            "   1.08028488e+02 -6.16300507e+01 -4.28915138e+01  1.37751922e-05]\n",
            " [-7.78304291e+01 -1.18709541e+02 -4.47407067e-01  2.63786926e+01\n",
            "  -1.33960905e+01 -6.53126297e+01  7.38083420e+01  1.31222885e-04]\n",
            " [-1.03989738e+02 -7.69521942e+01 -4.91601219e+01  6.13261642e+01\n",
            "  -9.37566185e+00  5.15351372e+01 -7.32220383e+01 -5.42867929e-06]\n",
            " [ 2.89654083e+01 -4.63039474e+01  8.64199829e+01 -1.08294006e+02\n",
            "  -7.66407318e+01  2.51792088e+01 -1.77386818e+01  7.79678812e-05]\n",
            " [-3.03564529e+01  4.74591522e+01 -2.39005184e+01 -3.52842827e+01\n",
            "   5.44207497e+01  9.90444107e+01  6.24765434e+01  6.79846853e-05]\n",
            " [-3.35199432e+01  1.36038040e+02 -9.98653183e+01 -2.95356598e+01\n",
            "  -5.82829666e+01 -4.82962875e+01 -4.29363251e+00  7.63870776e-05]\n",
            " [ 1.87369289e+01  9.88492966e+01  1.12727715e+02  1.09787422e+02\n",
            "  -1.43250341e+01  1.73302710e-01  3.84322429e+00 -6.82468526e-05]\n",
            " [ 2.15524002e+02 -5.34621506e+01 -6.13040276e+01  3.01284065e+01\n",
            "   9.57128716e+00 -6.93112135e-01 -1.98223591e+00 -2.94957310e-04]]\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-3ePfN11Cpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "bc0cb256-1d5c-4410-ddc1-88817086b937"
      },
      "source": [
        "from scipy import spatial\n",
        "for i in range(len(rbm_vectors)-1):\n",
        "    print(1-spatial.distance.cosine(rbm_vectors[i],rbm_vectors[7]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.20680926740169525\n",
            "-0.24124018847942352\n",
            "-0.32762065529823303\n",
            "-0.014096343889832497\n",
            "-0.24394436180591583\n",
            "-0.22100403904914856\n",
            "-0.11463432759046555\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}