{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "URBM_train_save_weights.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IrWLvXP_2jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsjkV-e2ITBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u24Zyq5FOcHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from __future__ import print_function\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_FkiE1mrS38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from python_speech_features import mfcc\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhEkb8RAaX8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessor\n",
        "# Here Bulk data is preprocessed to use in training\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s_AaIoqUcqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "834c662b-6c49-434e-9a48-0f58dd506809"
      },
      "source": [
        "shift = 1\n",
        "merge_limit=4\n",
        "dataset = []\n",
        "\n",
        "path_dir = \"/content/gdrive/My Drive/SpeakerVerification/Data/\" # this is the directory where all training data\n",
        "file_list=os.listdir(path_dir)\n",
        "\n",
        "print(file_list)\n",
        "for f in file_list:\n",
        "    if(f.endswith(\".wav\")):\n",
        "        print(f)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['file_example_WAV_2MG.wav', 'taunt.wav', 'StarWars60.wav', 'StarWars3.wav', 'ortalking.wav', '3peopletalking.wav', 'OSR_us_000_0010_8k.wav', 'OSR_us_000_0011_8k.wav', 'OSR_us_000_0012_8k.wav', 'OSR_us_000_0013_8k.wav', 'OSR_us_000_0030_8k.wav', 'OSR_us_000_0031_8k.wav', 'OSR_us_000_0032_8k.wav', 'OSR_us_000_0034_8k.wav', 'OSR_us_000_0035_8k.wav', 'OSR_us_000_0036_8k.wav', '2.wav', '3.wav']\n",
            "file_example_WAV_2MG.wav\n",
            "taunt.wav\n",
            "StarWars60.wav\n",
            "StarWars3.wav\n",
            "ortalking.wav\n",
            "3peopletalking.wav\n",
            "OSR_us_000_0010_8k.wav\n",
            "OSR_us_000_0011_8k.wav\n",
            "OSR_us_000_0012_8k.wav\n",
            "OSR_us_000_0013_8k.wav\n",
            "OSR_us_000_0030_8k.wav\n",
            "OSR_us_000_0031_8k.wav\n",
            "OSR_us_000_0032_8k.wav\n",
            "OSR_us_000_0034_8k.wav\n",
            "OSR_us_000_0035_8k.wav\n",
            "OSR_us_000_0036_8k.wav\n",
            "2.wav\n",
            "3.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_ujrlqDX-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "17efd038-7eff-478a-d74c-999cfe0b40a9"
      },
      "source": [
        "# for each file in the file list...\n",
        "for f in file_list:\n",
        "    if(f.endswith('.wav')==False):\n",
        "        continue\n",
        "        \n",
        "    path=os.path.join(path_dir,f)\n",
        "    # print(path)\n",
        "\n",
        "    (rate,sig) = wav.read(path)\n",
        "\n",
        "    # print(length)\n",
        "    mfcc_feat = mfcc(sig,rate,numcep=20,nfft=1200)\n",
        "\n",
        "    length = mfcc_feat.shape[0]\n",
        "\n",
        "\n",
        "    # print(length)\n",
        "    for i in range(length-merge_limit+1):\n",
        "        temp=list(mfcc_feat[i])+list(mfcc_feat[i+1])+list(mfcc_feat[i+2])+list(mfcc_feat[i+3])\n",
        "        dataset.append(temp)\n",
        "        # print(len(temp))\n",
        "\n",
        "\n",
        "augmented_dataset=np.array(dataset)                          # dataset\n",
        "# normalization\n",
        "augmented_dataset_mvn=preprocessing.scale(augmented_dataset) # augmented dataset\n",
        "print(augmented_dataset_mvn.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(67879, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5myF4wMhDMtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility functions for RBM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6SrhJ0ZxQiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def tf_x_init(fan_in, fan_out, dtype=np.float32):\n",
        "    k =  np.sqrt(6.0 / (fan_in + fan_out))\n",
        "    return tf.random_uniform((fan_in, fan_out), minval=-k, maxval=k, dtype=dtype)\n",
        "\n",
        "\n",
        "def sample_bernoulli(probs):\n",
        "    return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42AadQESyJki",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "**RBM using tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NNcGmW2yOjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class RBM:\n",
        "    def __init__(self,\n",
        "                 n_visible,\n",
        "                 n_hidden,\n",
        "                 learning_rate=0.001,\n",
        "                 momentum=0.95,\n",
        "                 err_function='mse',\n",
        "                 use_tqdm=False,\n",
        "                 # DEPRECATED:\n",
        "                 tqdm=None):\n",
        "        if not 0.0 <= momentum <= 1.0:\n",
        "            raise ValueError('momentum should be in range [0, 1]')\n",
        "\n",
        "       \n",
        "\n",
        "        self._use_tqdm = use_tqdm\n",
        "        self._tqdm = None\n",
        "\n",
        "        if use_tqdm or tqdm is not None:\n",
        "            from tqdm import tqdm\n",
        "            self._tqdm = tqdm\n",
        "\n",
        "        self.n_visible = n_visible\n",
        "        self.n_hidden = n_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.x = tf.placeholder(tf.float32, [None, self.n_visible])\n",
        "        self.y = tf.placeholder(tf.float32, [None, self.n_hidden])\n",
        "\n",
        "        self.w = tf.Variable(tf_x_init(self.n_visible, self.n_hidden), dtype=tf.float32)\n",
        "        self.visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n",
        "        self.hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n",
        "\n",
        "        self.delta_w = tf.Variable(tf.zeros([self.n_visible, self.n_hidden]), dtype=tf.float32)\n",
        "        self.delta_visible_bias = tf.Variable(tf.zeros([self.n_visible]), dtype=tf.float32)\n",
        "        self.delta_hidden_bias = tf.Variable(tf.zeros([self.n_hidden]), dtype=tf.float32)\n",
        "\n",
        "        self.update_weights = None\n",
        "        self.update_deltas = None\n",
        "        self.compute_hidden = None\n",
        "        self.compute_visible = None\n",
        "        self.compute_visible_from_hidden = None\n",
        "\n",
        "        self._initialize_vars()\n",
        "\n",
        "        assert self.update_weights is not None\n",
        "        assert self.update_deltas is not None\n",
        "        assert self.compute_hidden is not None\n",
        "        assert self.compute_visible is not None\n",
        "        assert self.compute_visible_from_hidden is not None\n",
        "\n",
        "        \n",
        "        self.compute_err = tf.reduce_mean(tf.square(self.x - self.compute_visible))\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def _initialize_vars(self):\n",
        "        pass\n",
        "\n",
        "    def get_err(self, batch_x):\n",
        "        return self.sess.run(self.compute_err, feed_dict={self.x: batch_x})\n",
        "\n",
        "\n",
        "\n",
        "    def partial_fit(self, batch_x):\n",
        "        self.sess.run(self.update_weights + self.update_deltas, feed_dict={self.x: batch_x})\n",
        "\n",
        "    def fit(self,\n",
        "            data_x,\n",
        "            n_epoches=10,\n",
        "            batch_size=10,\n",
        "            shuffle=True,\n",
        "            verbose=True):\n",
        "        assert n_epoches > 0\n",
        "\n",
        "        n_data = data_x.shape[0]\n",
        "\n",
        "        if batch_size > 0:\n",
        "            n_batches = n_data // batch_size + (0 if n_data % batch_size == 0 else 1)\n",
        "        else:\n",
        "            n_batches = 1\n",
        "\n",
        "        if shuffle:\n",
        "            data_x_cpy = data_x.copy()\n",
        "            inds = np.arange(n_data)\n",
        "        else:\n",
        "            data_x_cpy = data_x\n",
        "\n",
        "        errs = []\n",
        "\n",
        "        for e in range(n_epoches):\n",
        "            if verbose and not self._use_tqdm:\n",
        "                print('Epoch: {:d}'.format(e))\n",
        "\n",
        "            epoch_errs = np.zeros((n_batches,))\n",
        "            epoch_errs_ptr = 0\n",
        "\n",
        "            if shuffle:\n",
        "                np.random.shuffle(inds)\n",
        "                data_x_cpy = data_x_cpy[inds]\n",
        "\n",
        "            r_batches = range(n_batches)\n",
        "\n",
        "            if verbose and self._use_tqdm:\n",
        "                r_batches = self._tqdm(r_batches, desc='Epoch: {:d}'.format(e), ascii=True, file=sys.stdout)\n",
        "\n",
        "            for b in r_batches:\n",
        "                batch_x = data_x_cpy[b * batch_size:(b + 1) * batch_size]\n",
        "                self.partial_fit(batch_x)\n",
        "                batch_err = self.get_err(batch_x)\n",
        "                epoch_errs[epoch_errs_ptr] = batch_err\n",
        "                epoch_errs_ptr += 1\n",
        "\n",
        "            if verbose:\n",
        "                err_mean = epoch_errs.mean()\n",
        "                if self._use_tqdm:\n",
        "                    self._tqdm.write('Train error: {:.4f}'.format(err_mean))\n",
        "                    self._tqdm.write('')\n",
        "                else:\n",
        "                    print('Train error: {:.4f}'.format(err_mean))\n",
        "                    print('')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "            errs = np.hstack([errs, epoch_errs])\n",
        "\n",
        "        return errs\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.sess.run(self.w),\\\n",
        "            self.sess.run(self.visible_bias),\\\n",
        "            self.sess.run(self.hidden_bias)\n",
        "\n",
        "    def save_weights(self, filename, name):\n",
        "        saver = tf.train.Saver({name + '_w': self.w,\n",
        "                                name + '_v': self.visible_bias,\n",
        "                                name + '_h': self.hidden_bias})\n",
        "        return saver.save(self.sess, filename)\n",
        "\n",
        "    def set_weights(self, w, visible_bias, hidden_bias):\n",
        "        self.sess.run(self.w.assign(w))\n",
        "        self.sess.run(self.visible_bias.assign(visible_bias))\n",
        "        self.sess.run(self.hidden_bias.assign(hidden_bias))\n",
        "\n",
        "    def load_weights(self, filename, name):\n",
        "        saver = tf.train.Saver({name + '_w': self.w,\n",
        "                                name + '_v': self.visible_bias,\n",
        "                                name + '_h': self.hidden_bias})\n",
        "        saver.restore(self.sess, filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qVhAgqvySUe",
        "colab_type": "text"
      },
      "source": [
        "GRBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2aXzje7yWU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class GBRBM(RBM):\n",
        "    def __init__(self, n_visible, n_hidden, **kwargs):\n",
        "       \n",
        "\n",
        "        RBM.__init__(self, n_visible, n_hidden, **kwargs)\n",
        "\n",
        "    def _initialize_vars(self):\n",
        "\n",
        "        hidden_p = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n",
        "        visible_recon_p = tf.matmul(sample_bernoulli(hidden_p), tf.transpose(self.w)) + self.visible_bias\n",
        "        hidden_recon_p = tf.nn.sigmoid(tf.matmul(visible_recon_p, self.w) + self.hidden_bias)\n",
        "\n",
        "\n",
        "        positive_grad = tf.matmul(tf.transpose(self.x), hidden_p)\n",
        "        negative_grad = tf.matmul(tf.transpose(visible_recon_p), hidden_recon_p)\n",
        "\n",
        "        def f(x_old, x_new):\n",
        "            return self.momentum * x_old +\\\n",
        "                   self.learning_rate * x_new * (1 - self.momentum) / tf.to_float(tf.shape(x_new)[0])\n",
        "\n",
        "        delta_w_new = f(self.delta_w, positive_grad - negative_grad)\n",
        "        delta_visible_bias_new = f(self.delta_visible_bias, tf.reduce_mean(self.x - visible_recon_p, 0))\n",
        "        delta_hidden_bias_new = f(self.delta_hidden_bias, tf.reduce_mean(hidden_p - hidden_recon_p, 0))\n",
        "\n",
        "        update_delta_w = self.delta_w.assign(delta_w_new)\n",
        "        update_delta_visible_bias = self.delta_visible_bias.assign(delta_visible_bias_new)\n",
        "        update_delta_hidden_bias = self.delta_hidden_bias.assign(delta_hidden_bias_new)\n",
        "\n",
        "        update_w = self.w.assign(self.w + delta_w_new)\n",
        "        update_visible_bias = self.visible_bias.assign(self.visible_bias + delta_visible_bias_new)\n",
        "        update_hidden_bias = self.hidden_bias.assign(self.hidden_bias + delta_hidden_bias_new)\n",
        "\n",
        "        self.update_deltas = [update_delta_w, update_delta_visible_bias, update_delta_hidden_bias]\n",
        "        self.update_weights = [update_w, update_visible_bias, update_hidden_bias]\n",
        "\n",
        "        self.compute_hidden = tf.nn.sigmoid(tf.matmul(self.x, self.w) + self.hidden_bias)\n",
        "        self.compute_visible = tf.matmul(self.compute_hidden, tf.transpose(self.w)) + self.visible_bias\n",
        "        self.compute_visible_from_hidden = tf.matmul(self.y, tf.transpose(self.w)) + self.visible_bias\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npHdy2j3yk4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04ab2197-c056-4ba6-c606-a5ad7aa78280"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#name of the file where urbm model learned weights and biases will be saved.\n",
        "save_weights_path = \"/content/gdrive/My Drive/SpeakerVerification/SavedModels/urbm_model\" \n",
        "\n",
        "data=augmented_dataset_mvn\n",
        "lr  = 0.001\n",
        "input_dim =80 # 80\n",
        "hidden_dim = 400 # 200\n",
        "batch_size = 100\n",
        "nb_epoch = 100\n",
        "\n",
        "\n",
        "gbrbm = GBRBM(n_visible=input_dim, n_hidden=hidden_dim, learning_rate=lr, momentum=0.95, use_tqdm=True)\n",
        "errs = gbrbm.fit(data, n_epoches=nb_epoch, batch_size=batch_size)\n",
        "gbrbm.save_weights(save_weights_path,'weights')\n",
        "plt.plot(errs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-6a46016d1e11>:19: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "Epoch: 0: 100%|##########| 679/679 [00:02<00:00, 243.66it/s]\n",
            "Train error: 0.2634\n",
            "\n",
            "Epoch: 1: 100%|##########| 679/679 [00:01<00:00, 510.12it/s]\n",
            "Train error: 0.1314\n",
            "\n",
            "Epoch: 2: 100%|##########| 679/679 [00:01<00:00, 516.40it/s]\n",
            "Train error: 0.1042\n",
            "\n",
            "Epoch: 3: 100%|##########| 679/679 [00:01<00:00, 550.82it/s]\n",
            "Train error: 0.0953\n",
            "\n",
            "Epoch: 4: 100%|##########| 679/679 [00:01<00:00, 552.17it/s]\n",
            "Train error: 0.0920\n",
            "\n",
            "Epoch: 5: 100%|##########| 679/679 [00:01<00:00, 537.51it/s]\n",
            "Train error: 0.0908\n",
            "\n",
            "Epoch: 6: 100%|##########| 679/679 [00:01<00:00, 571.09it/s]\n",
            "Train error: 0.0905\n",
            "\n",
            "Epoch: 7: 100%|##########| 679/679 [00:01<00:00, 565.78it/s]\n",
            "Train error: 0.0906\n",
            "\n",
            "Epoch: 8: 100%|##########| 679/679 [00:01<00:00, 509.95it/s]\n",
            "Train error: 0.0909\n",
            "\n",
            "Epoch: 9: 100%|##########| 679/679 [00:01<00:00, 530.08it/s]\n",
            "Train error: 0.0910\n",
            "\n",
            "Epoch: 10: 100%|##########| 679/679 [00:01<00:00, 565.91it/s]\n",
            "Train error: 0.0914\n",
            "\n",
            "Epoch: 11: 100%|##########| 679/679 [00:01<00:00, 547.95it/s]\n",
            "Train error: 0.0915\n",
            "\n",
            "Epoch: 12: 100%|##########| 679/679 [00:01<00:00, 541.90it/s]\n",
            "Train error: 0.0918\n",
            "\n",
            "Epoch: 13: 100%|##########| 679/679 [00:01<00:00, 518.62it/s]\n",
            "Train error: 0.0920\n",
            "\n",
            "Epoch: 14: 100%|##########| 679/679 [00:01<00:00, 548.11it/s]\n",
            "Train error: 0.0923\n",
            "\n",
            "Epoch: 15: 100%|##########| 679/679 [00:01<00:00, 554.57it/s]\n",
            "Train error: 0.0925\n",
            "\n",
            "Epoch: 16: 100%|##########| 679/679 [00:01<00:00, 549.42it/s]\n",
            "Train error: 0.0926\n",
            "\n",
            "Epoch: 17: 100%|##########| 679/679 [00:01<00:00, 551.75it/s]\n",
            "Train error: 0.0929\n",
            "\n",
            "Epoch: 18: 100%|##########| 679/679 [00:01<00:00, 538.56it/s]\n",
            "Train error: 0.0929\n",
            "\n",
            "Epoch: 19: 100%|##########| 679/679 [00:01<00:00, 540.27it/s]\n",
            "Train error: 0.0931\n",
            "\n",
            "Epoch: 20: 100%|##########| 679/679 [00:01<00:00, 497.47it/s]\n",
            "Train error: 0.0932\n",
            "\n",
            "Epoch: 21: 100%|##########| 679/679 [00:01<00:00, 517.57it/s]\n",
            "Train error: 0.0934\n",
            "\n",
            "Epoch: 22: 100%|##########| 679/679 [00:01<00:00, 527.87it/s]\n",
            "Train error: 0.0935\n",
            "\n",
            "Epoch: 23: 100%|##########| 679/679 [00:01<00:00, 523.14it/s]\n",
            "Train error: 0.0935\n",
            "\n",
            "Epoch: 24: 100%|##########| 679/679 [00:01<00:00, 484.48it/s]\n",
            "Train error: 0.0935\n",
            "\n",
            "Epoch: 25: 100%|##########| 679/679 [00:01<00:00, 549.96it/s]\n",
            "Train error: 0.0936\n",
            "\n",
            "Epoch: 26: 100%|##########| 679/679 [00:01<00:00, 566.53it/s]\n",
            "Train error: 0.0938\n",
            "\n",
            "Epoch: 27: 100%|##########| 679/679 [00:01<00:00, 527.01it/s]\n",
            "Train error: 0.0938\n",
            "\n",
            "Epoch: 28: 100%|##########| 679/679 [00:01<00:00, 551.55it/s]\n",
            "Train error: 0.0939\n",
            "\n",
            "Epoch: 29: 100%|##########| 679/679 [00:01<00:00, 547.04it/s]\n",
            "Train error: 0.0940\n",
            "\n",
            "Epoch: 30: 100%|##########| 679/679 [00:01<00:00, 547.00it/s]\n",
            "Train error: 0.0942\n",
            "\n",
            "Epoch: 31: 100%|##########| 679/679 [00:01<00:00, 562.66it/s]\n",
            "Train error: 0.0940\n",
            "\n",
            "Epoch: 32: 100%|##########| 679/679 [00:01<00:00, 547.97it/s]\n",
            "Train error: 0.0941\n",
            "\n",
            "Epoch: 33: 100%|##########| 679/679 [00:01<00:00, 553.68it/s]\n",
            "Train error: 0.0941\n",
            "\n",
            "Epoch: 34: 100%|##########| 679/679 [00:01<00:00, 555.27it/s]\n",
            "Train error: 0.0943\n",
            "\n",
            "Epoch: 35: 100%|##########| 679/679 [00:01<00:00, 565.38it/s]\n",
            "Train error: 0.0943\n",
            "\n",
            "Epoch: 36: 100%|##########| 679/679 [00:01<00:00, 516.47it/s]\n",
            "Train error: 0.0942\n",
            "\n",
            "Epoch: 37: 100%|##########| 679/679 [00:01<00:00, 534.20it/s]\n",
            "Train error: 0.0941\n",
            "\n",
            "Epoch: 38: 100%|##########| 679/679 [00:01<00:00, 547.49it/s]\n",
            "Train error: 0.0943\n",
            "\n",
            "Epoch: 39: 100%|##########| 679/679 [00:01<00:00, 555.50it/s]\n",
            "Train error: 0.0943\n",
            "\n",
            "Epoch: 40: 100%|##########| 679/679 [00:01<00:00, 560.27it/s]\n",
            "Train error: 0.0943\n",
            "\n",
            "Epoch: 41: 100%|##########| 679/679 [00:01<00:00, 546.36it/s]\n",
            "Train error: 0.0944\n",
            "\n",
            "Epoch: 42: 100%|##########| 679/679 [00:01<00:00, 497.62it/s]\n",
            "Train error: 0.0943\n",
            "\n",
            "Epoch: 43: 100%|##########| 679/679 [00:01<00:00, 523.77it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 44: 100%|##########| 679/679 [00:01<00:00, 549.88it/s]\n",
            "Train error: 0.0944\n",
            "\n",
            "Epoch: 45: 100%|##########| 679/679 [00:01<00:00, 527.19it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 46: 100%|##########| 679/679 [00:01<00:00, 508.94it/s]\n",
            "Train error: 0.0944\n",
            "\n",
            "Epoch: 47: 100%|##########| 679/679 [00:01<00:00, 525.65it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 48: 100%|##########| 679/679 [00:01<00:00, 536.87it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 49: 100%|##########| 679/679 [00:01<00:00, 561.99it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 50: 100%|##########| 679/679 [00:01<00:00, 550.16it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 51: 100%|##########| 679/679 [00:01<00:00, 542.96it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 52: 100%|##########| 679/679 [00:01<00:00, 571.49it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 53: 100%|##########| 679/679 [00:01<00:00, 545.34it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 54: 100%|##########| 679/679 [00:01<00:00, 521.01it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 55: 100%|##########| 679/679 [00:01<00:00, 541.11it/s]\n",
            "Train error: 0.0947\n",
            "\n",
            "Epoch: 56: 100%|##########| 679/679 [00:01<00:00, 564.30it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 57: 100%|##########| 679/679 [00:01<00:00, 507.88it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 58: 100%|##########| 679/679 [00:01<00:00, 541.27it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 59: 100%|##########| 679/679 [00:01<00:00, 555.35it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 60: 100%|##########| 679/679 [00:01<00:00, 555.62it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 61: 100%|##########| 679/679 [00:01<00:00, 550.00it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 62: 100%|##########| 679/679 [00:01<00:00, 508.36it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 63: 100%|##########| 679/679 [00:01<00:00, 557.17it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 64: 100%|##########| 679/679 [00:01<00:00, 547.37it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 65: 100%|##########| 679/679 [00:01<00:00, 545.69it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 66: 100%|##########| 679/679 [00:01<00:00, 544.97it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 67: 100%|##########| 679/679 [00:01<00:00, 549.82it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 68: 100%|##########| 679/679 [00:01<00:00, 523.40it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 69: 100%|##########| 679/679 [00:01<00:00, 506.66it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 70: 100%|##########| 679/679 [00:01<00:00, 529.03it/s]\n",
            "Train error: 0.0947\n",
            "\n",
            "Epoch: 71: 100%|##########| 679/679 [00:01<00:00, 553.19it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 72: 100%|##########| 679/679 [00:01<00:00, 542.44it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 73: 100%|##########| 679/679 [00:01<00:00, 523.13it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 74: 100%|##########| 679/679 [00:01<00:00, 544.07it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 75: 100%|##########| 679/679 [00:01<00:00, 530.54it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 76: 100%|##########| 679/679 [00:01<00:00, 547.45it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 77: 100%|##########| 679/679 [00:01<00:00, 549.63it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 78: 100%|##########| 679/679 [00:01<00:00, 539.50it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 79: 100%|##########| 679/679 [00:01<00:00, 534.31it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 80: 100%|##########| 679/679 [00:01<00:00, 534.24it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 81: 100%|##########| 679/679 [00:01<00:00, 529.92it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 82: 100%|##########| 679/679 [00:01<00:00, 524.44it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 83: 100%|##########| 679/679 [00:01<00:00, 523.42it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 84: 100%|##########| 679/679 [00:01<00:00, 538.37it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 85: 100%|##########| 679/679 [00:01<00:00, 552.29it/s]\n",
            "Train error: 0.0944\n",
            "\n",
            "Epoch: 86: 100%|##########| 679/679 [00:01<00:00, 475.23it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 87: 100%|##########| 679/679 [00:01<00:00, 491.86it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 88: 100%|##########| 679/679 [00:01<00:00, 513.89it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 89: 100%|##########| 679/679 [00:01<00:00, 568.35it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 90: 100%|##########| 679/679 [00:01<00:00, 564.55it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 91: 100%|##########| 679/679 [00:01<00:00, 546.73it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 92: 100%|##########| 679/679 [00:01<00:00, 536.07it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 93: 100%|##########| 679/679 [00:01<00:00, 499.77it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 94: 100%|##########| 679/679 [00:01<00:00, 493.02it/s]\n",
            "Train error: 0.0946\n",
            "\n",
            "Epoch: 95: 100%|##########| 679/679 [00:01<00:00, 522.52it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 96: 100%|##########| 679/679 [00:01<00:00, 536.92it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 97: 100%|##########| 679/679 [00:01<00:00, 543.01it/s]\n",
            "Train error: 0.0945\n",
            "\n",
            "Epoch: 98: 100%|##########| 679/679 [00:01<00:00, 533.83it/s]\n",
            "Train error: 0.0944\n",
            "\n",
            "Epoch: 99: 100%|##########| 679/679 [00:01<00:00, 544.80it/s]\n",
            "Train error: 0.0944\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcmElEQVR4nO3deXwV9b3/8dcnCQmbYY2IhNXiAqhFU0RFKy5XxBZ/ttcWe/V2saWttdbb294L11qLVm2tvT/rVas8bK1Li3Vpe1GgWBDckB2RzUAIWxBI2EIgZDnnfO8fZ3I4CVlOTg6cDPN+Ph55ZOY735n5JJm8Z86cOTPmnENERIIhI90FiIjIiaPQFxEJEIW+iEiAKPRFRAJEoS8iEiBZ6Vpx79693aBBg9K1ehERX1q+fPke51xesvOnLfQHDRrEsmXL0rV6ERFfMrOtbZlfp3dERAJEoS8iEiAKfRGRAFHoi4gEiEJfRCRAFPoiIgGi0BcRCRDfhf7eQ9XMXr0z3WWIiPiS70L/G88t47t/XMH+wzXpLkVExHd8F/o79lcCEIro4S8iIq3lu9AXEZHkKfRFRAJEoS8iEiAKfRGRAFHoi4gEiG9D36Grd0REWsuHoW/pLkBExLd8GPoiIpIs34X+yAHdAeiQ4bvSRUTSznfJOWpQTwA6ZPmudBGRtFNyiogEiEJfRCRAfBv6zumSTRGR1vJd6Juu2BQRSZrvQl9ERJKn0BcRCRCFvohIgCj0RUQCxLehr2t3RERaz7ehLyIirafQFxEJEIW+iEiAKPRFRAJEoS8iEiAKfRGRAPFt6Ot+ayIiree70DfdcU1EJGkJhb6ZjTOzQjMrMrPJjUwfYGbzzWylmX1kZuNTX6qIiLRVi6FvZpnAE8B1wDDgZjMb1qDbT4CXnXMjgYnAk6kuVERE2i6RI/1RQJFzrtg5VwO8BNzQoI8Dcr3hbsAnqStRRERSJZHQ7wdsjxsv8dri/Qy4xcxKgFnA9xtbkJlNMrNlZrasrKwsiXJFRKQtUvVG7s3AH5xz+cB44AUzO2bZzrlpzrkC51xBXl5eilYtIiKJSiT0dwD948bzvbZ4twEvAzjnPgA6Ar1TUWCTdMmmiEirJRL6S4GhZjbYzLKJvlE7o0GfbcBVAGZ2DtHQPy7nb3TBpohI8loMfedcCLgDmAOsJ3qVzlozu8/MJnjd/h34lpmtAqYDX3NOH58SEWlvshLp5JybRfQN2vi2n8YNrwMuTW1pIiKSar77RK6IiCRPoS8iEiAKfRGRAPFt6Dtdsyki0mq+C33dZFNEJHm+C30REUmeQl9EJEAU+iIiAaLQFxEJEIW+iEiA+Db0dWcfEZHW813o64pNEZHk+S70RUQkeQp9EZEAUeiLiASIQl9EJEAU+iIiAeLb0NcVmyIiree70DfdZlNEJGm+C30REUmeQl9EJEAU+iIiAaLQFxEJEIW+iEiA+Db0nW6zKSLSar4LfV2xKSKSPN+FvoiIJE+hLyISIAp9EZEAUeiLiASIQl9EJEB8G/q6YFNEpPV8F/q6YlNEJHm+C30REUmeQl9EJEAU+iIiAZJQ6JvZODMrNLMiM5vcRJ8vmdk6M1trZn9KbZkiIpIKWS11MLNM4AngGqAEWGpmM5xz6+L6DAWmAJc65/ab2anHq2AREUleIkf6o4Ai51yxc64GeAm4oUGfbwFPOOf2AzjnSlNb5rF0k00RkdZLJPT7Advjxku8tnhnAmea2ftmtsjMxqWqwGPoNpsiIklr8fROK5YzFLgCyAfeMbNznXMH4juZ2SRgEsCAAQNStGoREUlUIkf6O4D+ceP5Xlu8EmCGc67WObcZ2EB0J1CPc26ac67AOVeQl5eXbM0iIpKkREJ/KTDUzAabWTYwEZjRoM/fiB7lY2a9iZ7uKU5hnSIikgIthr5zLgTcAcwB1gMvO+fWmtl9ZjbB6zYH2Gtm64D5wI+dc3uPV9EiIpKchM7pO+dmAbMatP00btgBP/S+RESknfLtJ3Kd7rMpItJqvgt9XbApIpI834W+iIgkT6EvIhIgCn0RkQBR6IuIBIh/Q18X74iItJrvQl/3WxMRSZ7vQl9ERJKn0BcRCRCFvohIgPgu9CurwwDURvROrohIa/ku9B+btxGAl5dub6GniIg05LvQrwp5R/rhSJorERHxH9+FvoiIJM93oe90Kl9EJGm+C/06+pCWiEjr+S70Q95VOzqlLyLSer4L/TpPvb0p3SWIiPiOb0NfRERaT6EvIhIgCn0RkQBR6IuIBIhCX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEAUeiLiASIQl9EJEAU+iIiAaLQFxEJEIW+iEiAKPRFRAJEoS8iEiAJhb6ZjTOzQjMrMrPJzfT7opk5MytIXYkiIpIqLYa+mWUCTwDXAcOAm81sWCP9TgF+ACxOdZEiIpIaiRzpjwKKnHPFzrka4CXghkb63Q/8EqhKYX0iIpJCiYR+P2B73HiJ1xZjZhcA/Z1zM5tbkJlNMrNlZrasrKys1cWKiEjbtPmNXDPLAP4b+PeW+jrnpjnnCpxzBXl5eW1dtYiItFIiob8D6B83nu+11TkFGAEsMLMtwGhght7MFRFpfxIJ/aXAUDMbbGbZwERgRt1E51y5c663c26Qc24QsAiY4JxbdjwKvv68vsdjsSIigdBi6DvnQsAdwBxgPfCyc26tmd1nZhOOd4EN9e6SfaJXKSJy0shKpJNzbhYwq0HbT5voe0Xby2rajgNHjufiRUROar77RG5FVSjdJYiI+JbvQn/8uTqnLyKSLN+Ffp/cnHSXICLiW74L/QyzdJcgIuJbCn0RkQDxXehnZij0RUSS5bvQ14G+iEjyfBf6Or0jIpI834W+Tu+IiCTPd6GvA30RkeT5LvQH9eqS7hJERHzLd6F/evdO6S5BRMS3fBf6IiKSPF+HfmmFHscrItIavg79g0dq012CiIiv+Dr01+w4mO4SRER8xdeh//aGsnSXICLiK74O/eKyQ+kuQUTEV3wd+qtKytNdgoiIr/g69EVEpHUU+iIiAaLQFxEJEIW+iEiAKPRFRAJEoS8iEiAKfRGRAFHoi4gEiO9DvzoUTncJIiK+4fvQn/HhJ+kuQUTEN3wf+i7dBYiI+IjvQ19ERBLn+9C3dBcgIuIjvgz9n31+WGxYp3dERBLny9CPD/pwRLEvIpIoX4Z+zy7ZseFM0wkeEZFE+TL0LxrcK90liIj4ki9DPzPj6NG9DvRFRBKXUOib2TgzKzSzIjOb3Mj0H5rZOjP7yMzmmdnA1Jd6VN4pObHhjaV6Tq6ISKJaDH0zywSeAK4DhgE3m9mwBt1WAgXOufOAV4GHU11oU6a9U3yiViUi4nuJHOmPAoqcc8XOuRrgJeCG+A7OufnOuUpvdBGQn9oym3eoOnQiVyci4luJhH4/YHvceInX1pTbgNmNTTCzSWa2zMyWlZWVJV5lC/YfrknZskRETmYpfSPXzG4BCoBfNTbdOTfNOVfgnCvIy8tL5apFRCQBiYT+DqB/3Hi+11aPmV0N3A1McM5Vp6a8xDw6dyO7D1adyFWKiPhSIqG/FBhqZoPNLBuYCMyI72BmI4GniQZ+aerLbN5rK0oY+8iCE71aERHfaTH0nXMh4A5gDrAeeNk5t9bM7jOzCV63XwFdgVfM7EMzm9HE4o6byho9TEVEpCVZiXRyzs0CZjVo+2nc8NUprktERI4DX34iF+ArFw1IdwkiIr7j29C/6uxT012CiIjv+Db0M3TTHRGRVvNt6A/s1TndJYiI+I5vQ39IXtdj2m55ZjGLi/cy86OdaahIRKT9S+jqHb94r2gP7xXtAeD6865PczUiIu2Pb4/0RUSk9RT6KbB9XyVVtfpwmEhzqkNhFhXvTXcZgefr0B9+em6Lfapqw0TiHp5eXllbb7ytQuEIlz08nzunr0zZMo+Xldv2c9GDcyk/UpvwPJvKDvHMu8k9s2DvoWqeebcY5/TweoH731jHxGmLKNxVke5SAs3Xof+f485udnplTYiz7/k7v3qzkL+v2UVZRTXn3/cmj87dUK/f9n2VPLdwS1I11MXZWx83fcuhcMTx2wWbuOmphcfO7xxPvb2J0kZuGHeoOpT0Dqr8SC3vbqx/++rojemqWbF1f6yuxtYb76anPuDnM9cn9Urm315exc9nrmfNjoOtnjfVtu+r5Ox7ZlPUjp60tmLbfiqqju6Ad5VXUbK/spk5UqOsojotFzvUhf2BSt0KPZ18HfqXn9n07ZkHTZ7Jfa+vA+C3CzbxnReX88T8IgBmr9kV67dw0x4ue3g+985Yy8pt+1m5bT9fePJ9Zq3eSU0o0mINdZ8XiMQdzYbCEV5ctJVQODr/Gf81i1/+/WOWbtlfb979h2vYsPsQv5j9MVc8soA3PvqEWm+e8spaRtw7h/Pve5Ofv7GONTvKqaoN886GMsINdgSRiOOqXy9gxqpPKK+sZe+has6f+ia3/m4J724soyYU4Rt/WMrbG6I7Aeftqv7/PzYw6sF5zd6h9HACD6j54+KtzF59NEQ+OXCEUDgSC7SacOM7jHDExZ6FsHzrfmrDEQ5Vh+oF34Oz1vPQrPUt1tCSNz7aSVVthFeWb2+yz6HqEB9sav70w4LCUtbvjO7EqkNhtu87Wuuba3dx/tQ3m91BFu6qYFHxXo7UhPnCkwuZ9Pzy2LTRD81jzC/nx8bDEXfMq6TVJeWs2VEOQGlFFdWh1u+Mv/6HJXzvTyta9YqvoZpQpN4OKxF1P4p5/zPlR2rZVd70tldVG2Z+MwdTjRn7yAKGTJlJZc2Jf7DSDY+/x5+Xbjvh622tk+rqnYZeWlr/H3ymF0x1Ab2gsJSvPbs0Nv3GJ48eid/+xxVcfU4fvnnZYB6du4FFxft4+Ivn8aXP9Kc2HGHD7goyM4wzTz3FW2b0qH3ya6vZUFrBym0HomE7ZnC9Gl5ctJVbRg/kfz/cwQ9e+pDvjT0DiN4w7o4/HT1F9O3LhwBQURXimfc288x7m2PTplx3Nt/+7BnsO1xD15wsjtSG2VR2uNFTTJv3HOZwdajeK5G6f755XltZRTV9cjvyyYEjmEHpwWpueOJ9bh41oNGdGsDG3RV069yBx98q4vkPtgLw8f3jWFBYxndeXF6vb8RBRVUtnbOzOOO/ZnHt8D48fWsBX/39ktjVVgDZmRkM7t2Fwt0VfDDlSt5YtTP2OMxt+yqZesNwTj2lIwC14QjvbdzDFWflYWbM/7iUgb06U1ZRTX7PzhyuDnFmn1Niy64LqLnrdvP028W8+x9j6d+zM998bimLi/fxwjcv4vG3ipi7fjdL7r4qth6AV5eXsKnsEP857uzY9rLlF9fzwz+vYubqnay85xrW7TzIpBeiP/fU19dx19VD6dapA1W1Ybp3zo4t69pH3wFgzdRrAfigeC/hiCMzo/6HDZ9+exMPzf6Yz56Zxx1XfoqR/buTlZnB5x9/L7b+UQ/MY+xZeTz79VH8fc0u8nt0YvjpuTy5YBN5XXO4/Mw8TuvWkYZ27D8CQOnBKn4xez33fn44HTtk4pwj4jimljpb9hymOhThrNNO4dbfLWbx5n1s+UX0Krmyimq65GSyoLCMQ9Uhlm/Zz4h+udx4QT5TZ6zlns8Pi70q/tLTH/DCbaP4/vSVHKisjS2jtKKKH7/yEY/dPJJunTrw4Kz1PP/BVv56+yUM6NmZ+YVlXDiwBz27ZLNhdwXn5XcjJyszVt+Ie+fEnqJ310sfMu1fC9hzqJqq2jD5PToz+sF5dMrO5G+3X0qn7Eyys+of8xaVVjDh8fd5898up1/3TmzZW8naT8r53HmnN/r7uOmphRQM6hk747CqpJxVJav58meit4ipqKpl3+EaBvbqQlVtmKraMK9/tJP/mbeRJXen73Zllq7zrQUFBW7ZsmVtXs6gyTOTmm9gr85s3dv6l9ILfnQFV8TdxvnV71zMPz/1QaN9u3fuwPRvjea637xbr/3MPl3ZsDv50wyZGXbM0X5znrrlAr7z4oompz/+lZHs2H+Eh2Z/3GSfG0f2468ro49ReOG2Udz6uyUJr/+2MYP53XubufqcPsxdvxuAnKwMqhN4JRXvXy4awAM3nlvvb96veyd2HDjSaP/5P7qC7764nOI9hxt91bZoylWMfmjeMct64MYR3P3XNQB8/dJBPPv+FgDm3HV5LLRX3ftPnD/1TQA6Z2e2eJfX30z8NNv2VvLrf2xodHr8embeOYbrH3uv3vQvXpDPpMuHxNa/duq1DL93DgALJ1/JJb9465hlZmUY0yeNZsnmfew7XMNlQ3tTE4rEdk51xp97GhPO78eMVTuYtXoXK++5hh5dstm+r5KcDhnc9odljOjXjelLokexS+++ms88MBeAwp+PIxR2sVqScdfVQ3l07sZ6ba9852Ju8v6vpt164TE1A1w4sAfPfWMUa3eUc9GQXvW2i9yOWTxy0/mx+b439gyemL+p3vzPfu0zHK4Jcd/r63jjzjGMeiC6LeT36ETJ/qPb1P3/bwQTzj+d0oNVbNtXyRl5XfnkwBG+8sxiADpkGhM/M4AXFm2NzTPt1gv51ZxCNpYe4pbRA3hxUf1XAAsnX8np3Tu1+ncFYGbLnXMFSc3MSRD6j8wp5HHvtI2IpMaky4fEXmVJ6j3zrwVcPaxPUvO2NfR9fU4f4EfXnpXuEkROOgr846upU2gngu9DH+ALI5t7TruISPvS3NV+x9tJEfr//eVPp7sEEZGExZ//P9FOitAHGDW4Z7pLEBFp906a0H/52xfHLn8UEZHGnTShD/Dja5v/hK6ISNCdVKEPsPmh8fzwmjPTXYaISJNev2NM2tZ90oW+mXHnVUN58baL0l1Ku9Lw04dNyfH6jflU7yb7tHTPo7Zq7qH30269EID7bxhOv7gPt4wc0J0p1x2tq09uTrPr6NapQ6PtdT9/IjfzS1SyV+cVDOxR78q03l1zeOgL5yY0b88u2Y22XzfitFbXcemnejU7/fpz+3LxkKb7dO/c+O+6te753LB643ePP4cvF/TnsqFHt9Vz+ubypYJ8fv+1AhZOvjLhZfdq4vfVVlMnDI8Nn5ffLTZ8btzwieb7D2c1JxxxlOyv5PTunVi6ZR+PzClkxbYDCc//s88P4+y+ueR27MCs1Tt5Zfl2xp51Kiu27efST/WOfYLyirPyuG/CCMLOMfaRBeR2zOKhL5zHtHc20Sk7k+9fOZQLB/YgJyuDwVNmNbqu8eeexo0j87n6nFMxM/6yooRPDhzhny/sT6+u2by2vISLhvRiYM/O1IQjLCreS0VViAE9O/PaihKe/2Arr333Evrk5tCrSw6dsjP59ZuF/M9bRSz/ydX06no0BCMRx5HaMF1yjt6FwzmHmVETilBaUUV+j+jjKCtrQtSGHN0a/OOWVlSRYcb0xdvok9uRmnCEn/xtDXdeNZQ7r/wUoUj0RnKPzt3IX26/hGff38J3P3sGw7wwHTxlJs5Fw/vsvrnsKq/i2uGnJbxzasqCwlLOy+9Ozy7ZrNp+gNv/uIJZP7iMJ+cXMXJAD64651QWbtrLZ737NkUijohzZGU2vt6563YzOK8LQ3p3YfOewwzJ68oz7xZz7fDT6N+zM0u37KM2HKFPbkfOiHua2/Z9lew7XMOIft3qXZO9fudBuuZksansEKd07MAXf7uQmXeOIa9rDhkZRlfvb9KxQ+YxtTT04fYDZGUYI/q1LkCqQ2E+3lnB+f27H9Oek5VJ6cEqpi/Zzr+MHsCGXRVc0uAAYHVJOatKDnDR4J4MjbvVhXOOHQeO0LdbpxavQ6+7keAn5UfokJlBn9zo7SLKj9RSXllL/57RHbqZ4ZzDOchoZpm14QiHq0P1bnkRLxSOkGFGRoZxpCZMVqZRVRsmFHb08AK/OhQmOzMjts7pS7Yz9uw85q7bzS2jB8buGQTReygN7t2FbfsOk9upA4uK93HJGb3YureSYX1z6ZR99O9XHQpjWJu37TqB/0RuMiIRRyji6v0RZq3eydizTq33x2rJq8tLOC23I2PijjSeXFDEuOGnNfo4R4jeYbBzdhbZWRmUV9ZSG4mQ27FDmzaISMRRHYocU3sk4jhYVdvkP0I6lVfWEopE6u2MRKRlCn0RkQAJ/G0YREQkcQp9EZEAUeiLiASIQl9EJEAU+iIiAaLQFxEJEIW+iEiAKPRFRAIkbR/OMrMyINknCfQG9qSwnBNBNZ8Yqvn481u9cHLVPNA5l5fsQtMW+m1hZsva8om0dFDNJ4ZqPv78Vi+o5ng6vSMiEiAKfRGRAPFr6E9LdwFJUM0nhmo+/vxWL6jmGF+e0xcRkeT49UhfRESSoNAXEQkQ34W+mY0zs0IzKzKzyWlY/+/NrNTM1sS19TSzf5jZRu97D6/dzOwxr9aPzOyCuHm+6vXfaGZfjWu/0MxWe/M8ZvHPaEuu3v5mNt/M1pnZWjP7gQ9q7mhmS8xslVfzVK99sJkt9tbzZzPL9tpzvPEib/qguGVN8doLzezauPaUb0dmlmlmK83sDT/U6y13i/e3+9DMlnlt7Xnb6G5mr5rZx2a23swubuf1nuX9buu+DprZXWmtOfr8SX98AZnAJmAIkA2sAoad4BouBy4A1sS1PQxM9oYnA7/0hscDswEDRgOLvfaeQLH3vYc33MObtsTra96817Wx3r7ABd7wKcAGYFg7r9mArt5wB2Cxt/yXgYle+1PAd73h24GnvOGJwJ+94WHeNpIDDPa2nczjtR0BPwT+BLzhjbfrer11bgF6N2hrz9vGc8A3veFsoHt7rrdB7ZnALmBgOms+YWGZol/axcCcuPEpwJQ01DGI+qFfCPT1hvsChd7w08DNDfsBNwNPx7U/7bX1BT6Oa6/XL0W1/y9wjV9qBjoDK4CLiH46MavhtgDMAS72hrO8ftZw+6jrdzy2IyAfmAdcCbzhrb/d1hu3rC0cG/rtctsAugGb8S5Aae/1NlL/PwHvp7tmv53e6Qdsjxsv8drSrY9zbqc3vAvo4w03VW9z7SWNtKeEdxphJNEj53Zds3eq5EOgFPgH0SPdA865UCPridXmTS8HeiXxs7TFo8B/ABFvvFc7r7eOA940s+VmNslra6/bxmCgDHjWO432jJl1acf1NjQRmO4Np61mv4V+u+eiu9t2dx2smXUFXgPucs4djJ/WHmt2zoWdc58megQ9Cjg7zSU1ycw+B5Q655anu5YkjHHOXQBcB3zPzC6Pn9jOto0soqdWf+ucGwkcJnpqJKad1RvjvZ8zAXil4bQTXbPfQn8H0D9uPN9rS7fdZtYXwPte6rU3VW9z7fmNtLeJmXUgGvh/dM79xQ8113HOHQDmEz3F0d3MshpZT6w2b3o3YG8SP0uyLgUmmNkW4CWip3h+047rjXHO7fC+lwJ/JbqDba/bRglQ4pxb7I2/SnQn0F7rjXcdsMI5t9sbT1/NqTpfdSK+iO7pi4m+zKt7Q2t4GuoYRP1z+r+i/psyD3vD11P/TZklXntPoucme3hfm4Ge3rSGb8qMb2OtBjwPPNqgvT3XnAd094Y7Ae8CnyN6lBT/xujt3vD3qP/G6Mve8HDqvzFaTPTNtOO2HQFXcPSN3HZdL9AFOCVueCEwrp1vG+8CZ3nDP/Nqbbf1xtX9EvD19vD/d0LDMkW/vPFEr0DZBNydhvVPB3YCtUSPPG4jej52HrARmBv3xzDgCa/W1UBB3HK+ARR5X/EbQwGwxpvncRq8aZVEvWOIvnT8CPjQ+xrfzms+D1jp1bwG+KnXPsTbwIuIBmqO197RGy/ypg+JW9bdXl2FxF3VcLy2I+qHfruu16tvlfe1tm657Xzb+DSwzNs2/kY0ANttvd4yuxB9Jdctri1tNes2DCIiAeK3c/oiItIGCn0RkQBR6IuIBIhCX0QkQBT6IiIBotAXEQkQhb6ISID8H90+cVJAucRZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuwGwKJwJ_fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbrbm = GBRBM(n_visible=input_dim, n_hidden=hidden_dim, learning_rate=lr, momentum=0.95, use_tqdm=True)\n",
        "print(gbrbm.get_weights())\n",
        "gbrbm.load_weights(save_weights_path,'weights')\n",
        "print(gbrbm.get_weights())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}